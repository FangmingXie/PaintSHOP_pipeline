
# final pipeline endpoint
rule all:
    input:
        'pipeline_output/DONE.txt'

version = config['version']
DENOVO_DIR = config['denovo_dir']  #"pipeline_output/02_intermediate_files/02_init_probes"

INTERM_DIR = f"pipeline_output/02_intermediate_files_{version}"
OUT_DIR =    f"pipeline_output/03_output_files_{version}"

BOWTIE2_DIR =    f'pipeline_output/01_reference_files/06_bowtie2_indices/{config["assembly"]}'
JELLYFISH_IDX =  f"pipeline_output/01_reference_files/07_jf_files/{config['assembly']}.jf"
ANNOT_BED =      f'pipeline_output/01_reference_files/05_annotation_files/{config["assembly"]}.bed'
ANNOT_FLAT_BED = f'pipeline_output/01_reference_files/05_annotation_files/{config["assembly"]}_iso_flat.bed' 
MULTI_FASTA =    f'pipeline_output/01_reference_files/02_multi_fasta/{config["assembly"]}.fa'
CHROM_NAMES =    f'pipeline_output/01_reference_files/01_chrom_names/chrom_names.txt'
CHROM_FASTA_DIR = 'pipeline_output/01_reference_files/03_chrom_fastas'

checkpoint split_chroms:
    input:
        multi_fasta=MULTI_FASTA,
        chrom_names=CHROM_NAMES,
    output:
        chrom_fasta_dir=directory(CHROM_FASTA_DIR),
    conda:
        'envs/environment.yml'
    params:
        mfree='30G',
        h_rt='3:0:0'
    script:
        'scripts/split_chroms.py'

# align probes to reference genome
rule align_probes:
    input:
        f'{DENOVO_DIR}/{{chrom}}.fastq',
        f'{BOWTIE2_DIR}/{config["assembly"]}.1.bt2',
        f'{BOWTIE2_DIR}/{config["assembly"]}.2.bt2',
        f'{BOWTIE2_DIR}/{config["assembly"]}.3.bt2',
        f'{BOWTIE2_DIR}/{config["assembly"]}.4.bt2',
        f'{BOWTIE2_DIR}/{config["assembly"]}.rev.1.bt2',
        f'{BOWTIE2_DIR}/{config["assembly"]}.rev.2.bt2',
    output:
        f'{INTERM_DIR}/03_alignments/{{chrom}}.bam'
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='5:0:0'
    threads: config.get('bowtie2_threads', 4)
    shell:
        f'bowtie2 -x {BOWTIE2_DIR}/{config["assembly"]} -U {{input[0]}} --threads {{threads}} --very-sensitive-local -k 100 | '
        'samtools view -bS - > {output}'

# extract duplex information from alignment results
rule sam_to_pairwise:
    input:
        rules.align_probes.output
    output:
        f'{INTERM_DIR}/04_pairwise_alignments/{{chrom}}_pairwise.out'
    conda:
        'envs/environment.yml'
    params:
        mfree='12G',
        h_rt='3:0:0'
    shell:
        'samtools view {input} | sam2pairwise > {output}'

# extract alignment scores from pairwise alignment
rule extract_alignment_scores:
    input:
        rules.align_probes.output
    output:
        f'{INTERM_DIR}/05_alignment_scores/{{chrom}}_AS.txt'
    conda:
        'envs/environment.yml'
    params:
        mfree='12G',
        h_rt='3:0:0'
    shell:
        "samtools view {input} | awk '{{print $12}}' > {output}"

# construct alignment dataframe using pairwise alignment info
rule parse_pairwise:
    input:
        rules.sam_to_pairwise.output,
        rules.extract_alignment_scores.output
    output:
        f'{INTERM_DIR}/06_data_frames/{{chrom}}_alignments.csv'
    conda:
        'envs/environment.yml'
    params:
        mfree='85G',
        h_rt='3:0:0'
    script:
        'scripts/parse_pairwise.py'

# predict duplexing probabilities using pre-trained XGBoost model
rule predict_duplex:
    input:
        rules.parse_pairwise.output,
        f'{workflow.basedir}/pickled_models/{config.get("model_temp", 42)}_all_fixed_xgb.pickle.dat'
    output:
        f'{INTERM_DIR}/07_predictions/{{chrom}}_predictions.csv'
    conda:
        'envs/environment.yml'
    params:
        mfree='30G',
        h_rt='3:0:0'
    script:
        'scripts/XGB_predict.py'

# score probes based on XGBoost output
rule score:
    input:
        rules.predict_duplex.output
    output:
        f'{INTERM_DIR}/08_scored_probes/{{chrom}}_probes.bed'
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='3:0:0'
    script:
        'scripts/output_bed.py'

# remove any probes that contain "N" (sometimes introduced via bowtie2/sam2pairwise)
rule filter_n_probes:
    input:
        rules.score.output
    output:
        f'{INTERM_DIR}/09_probes_filtered/{{chrom}}_probes.bed'    
    conda:
        'envs/environment.yml'
    params:
        mfree='12G',
        h_rt='3:0:0'
    shell:
        "awk '$4 !~ /N/ && $4 !~ /-/' {input} > {output}"

# determine max kmer frequency using jellyfish
rule max_kmer:
    input:
        rules.filter_n_probes.output,
        JELLYFISH_IDX,
    output:
        f'{INTERM_DIR}/10_max_kmer_counts/{{chrom}}_kmer_max.txt'
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='3:0:0'
    script:
        'scripts/kmer_frequency.py'

# calculate prob value using nupack
rule calc_prob:
    input:
        rules.filter_n_probes.output,
    output:
        f'{INTERM_DIR}/11_prob_values/{{chrom}}_prob.txt'
    conda:
        'envs/environment.yml'
    params:
        mfree='12G',
        h_rt='6:0:0'
    script:
        'scripts/calc_prob.py'

# output final probe set
rule final_probes:
    input:
        rules.calc_prob.output,
        rules.max_kmer.output
    output:
        f'{OUT_DIR}/01_dna_probes/{config["assembly"]}_all_newBalance_{{chrom}}.tsv'
    conda:
        'envs/environment.yml'
    params:
        mfree='12G',
        h_rt='3:0:0'
    script:
        'scripts/append_max_kmers.py'

# aggregate paths to dynamically created files
def get_probe_paths(wildcards):

    # construct wild card path to checkpoint output files
    wildcard_path = os.path.join(
        checkpoints.split_chroms.get(**wildcards).output[0], 
        '{chrom}.fa'
    )

    # construct paths to downstream files to be aggregated
    file_paths = expand(
        rules.final_probes.output[0],
        chrom=glob_wildcards(wildcard_path).chrom
    )

    # success
    return(file_paths)

# merge probes for each chromosome
rule merge_probes:
    input:
        get_probe_paths
    output:
        f'{OUT_DIR}/01_dna_probes/{config["assembly"]}_all_newBalance.tsv',
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='3:0:0'
    shell:
        'for file in {input}; do cat $file >> {output}; done'

# zip probe files for each chromosome for PaintSHOP resources upload
rule zip_probes:
    input:
        rules.merge_probes.output
    output:
        f'{OUT_DIR}/04_zip_archives/{config["assembly"]}_all_newBalance.zip'
    conda:
        'envs/environment.yml'
    params:
        mfree='10G',
        h_rt='3:0:0'
    shell:
        'zip -r -j {output} {input}'

# generate probe database using bedtools intersect
rule gen_refseq_db:
    input:
        probes=get_probe_paths,
        annotations=ANNOT_BED,
    output:
        tsv=f'{OUT_DIR}/02_rna_probes_all/{config["assembly"]}_refseq_newBalance.tsv'
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='3:0:0'
    script:
        'scripts/probeDB.py'

# zip probe files for each chromosome for PaintSHOP resources upload
rule zip_refseq_db:
    input:
        rules.gen_refseq_db.output.tsv
    output:
        f'{OUT_DIR}/04_zip_archives/{config["assembly"]}_refseq_newBalance.zip'
    conda:
        'envs/environment.yml'
    params:
        mfree='10G',
        h_rt='3:0:0'
    shell:
        'zip -r -j {output} {input}'

# generate probe database using bedtools intersect
rule gen_iso_db:
    input:
        probes=get_probe_paths,
        annotations=ANNOT_FLAT_BED, 

    output:
        tsv=f'{OUT_DIR}/03_rna_probes_iso/{config["assembly"]}_iso_newBalance.tsv'
    conda:
        'envs/environment.yml'
    params:
        mfree='20G',
        h_rt='3:0:0'
    script:
        'scripts/probeDB.py'

# zip probe files for each chromosome for PaintSHOP resources upload
rule zip_iso_db:
    input:
        rules.gen_iso_db.output.tsv
    output:
        f'{OUT_DIR}/04_zip_archives/{config["assembly"]}_iso_newBalance.zip'
    conda:
        'envs/environment.yml'
    params:
        mfree='10G',
        h_rt='3:0:0'
    shell:
        'zip -r -j {output} {input}'

# success
rule finish:
    input:
        rules.zip_probes.output,
        rules.zip_refseq_db.output,
        rules.zip_iso_db.output,
    output:
        f'pipeline_output/DONE.txt'
    params:
        mfree='10G',
        h_rt='3:0:0'
    shell:
        'touch {output}'
